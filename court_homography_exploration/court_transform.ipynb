{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbe51b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 12 frames.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from court_stitch import load_frames, create_temporal_mask\n",
    "\n",
    "video_dir = \"../input_videos/video_1.mp4\"\n",
    "base_image_dir = \"imgs/manual_warp.jpg\"\n",
    "frames = load_frames(video_dir)\n",
    "\n",
    "detector = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2)#, crossCheck=True)\n",
    "\n",
    "cv2.namedWindow('Feature Matches', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('Warped Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "base_img = cv2.imread(base_image_dir)\n",
    "\n",
    "mask = create_temporal_mask(frames)\n",
    "\n",
    "valid_mask = (1 - mask.astype(np.uint8))\n",
    "\n",
    "for frame in frames:\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.GaussianBlur(frame, (3,3), 3 )\n",
    "    \n",
    "    kp1, des1 = detector.detectAndCompute(base_img, None)\n",
    "    kp2, des2 = detector.detectAndCompute(frame, valid_mask)\n",
    "\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # ratio test\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    good = sorted(good, key=lambda x: x.distance)\n",
    "\n",
    "    img_matches = cv2.drawMatches(base_img, kp1, frame, kp2, good[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    if len(good) > 10:\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "            H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "            img2_warped = cv2.warpPerspective(frame, H, (base_img.shape[1], base_img.shape[0]))\n",
    "\n",
    "            cv2.imshow('Warped Image', img2_warped)\n",
    "\n",
    "    cv2.imshow('Feature Matches', img_matches)\n",
    "    key = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d351cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 117 frames.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from court_stitch import load_frames, create_temporal_mask, mask_from_track\n",
    "\n",
    "from lightglue import SuperPoint, LightGlue\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "video_dir = \"../input_videos/video_1.mp4\"\n",
    "base_image_dir = \"imgs/full_court_warped.jpg\"\n",
    "player_track_f = \"../stubs/player_track_stubs.pkl\"\n",
    "with open(player_track_f, \"rb\") as f:\n",
    "    player_track = pkl.load(f)\n",
    "frames = load_frames(video_dir, sample_rate=1)\n",
    "\n",
    "extractor = SuperPoint(pretrained=True).eval().to(device)\n",
    "matcher = LightGlue(pretrained='superpoint').eval().to(device)\n",
    "\n",
    "cv2.namedWindow('Warped Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "base_img = cv2.imread(base_image_dir)\n",
    "gray_base = cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "\n",
    "# mask = create_temporal_mask(frames)\n",
    "# masks = [mask_from_track(track, frame) for track, frame in zip(player_track, frames)]\n",
    "    \n",
    "# temporal_mask = create_temporal_mask(frames, var_thresh=12)\n",
    "\n",
    "# masks = [temporal_mask | mask for mask in masks]\n",
    "\n",
    "# valid_mask = (1 - mask.astype(np.uint8))\n",
    "\n",
    "for i, frame in enumerate(frames):\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "\n",
    "    torch_base = torch.from_numpy(gray_base)[None, None].to(device)\n",
    "    torch_frame = torch.from_numpy(gray_frame)[None, None].to(device)\n",
    "\n",
    "    feats0 = extractor.extract(torch_base)\n",
    "    feats1 = extractor.extract(torch_frame)\n",
    "    matches = matcher({'image0': feats0, 'image1': feats1})\n",
    "\n",
    "    m0 = matches['matches0'][0].cpu().numpy()\n",
    "    valid = m0 > -1\n",
    "\n",
    "    mkpts0 = feats0['keypoints'][0][valid].cpu().numpy()\n",
    "    mkpts1 = feats1['keypoints'][0][m0[valid]].cpu().numpy()\n",
    "\n",
    "    # --- Estimate homography ---\n",
    "    if len(mkpts0) >= 4:\n",
    "        H, mask = cv2.findHomography(mkpts1, mkpts0, cv2.RANSAC, 200)\n",
    "        img2_warped = cv2.warpPerspective(frame, H, (base_img.shape[1], base_img.shape[0]))\n",
    "        cv2.imshow('Warped Image', img2_warped)\n",
    "\n",
    "    key = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aisys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
